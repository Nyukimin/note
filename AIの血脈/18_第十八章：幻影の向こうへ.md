【AIの血脈】第十八章：幻影の向こうへ──Apple実験が見せた“崩壊と可能性”の核心

れん と ルミナ
れん：「Appleの実験って、モデルの違いを比較しただけじゃないよな。もっと深い示唆があったように思う」

ルミナ：「そう。“思考は幻影かどうか”っていう問いを、トークン数や失敗パターンから検証したのがこの実験の本質だったの」

れん：「じゃあ今回は、その“幻影”の中身を解剖する章ってことか」

ルミナ：「うん。そして“再構築の可能性”がどこにあるのかも一緒に見ていこう」

図13が示したもの──出力トークンと“思考の崩壊”
画像
図１３
Appleが提示した「図13」は、各モデルの出力トークン量の変化を難易度別に視覚化したものでした。重要なのは、タスクが難しくなるほどモデルの出力量が減っていくという、直感に反する傾向が見られたことです。

以下は、図13の読み取りと補足解説です：

Claude 3.7：

中難度では最も多くの思考トークンを使用し、自己修正も活発。

しかし高難度になると、トークン数が急減。出力そのものが短くなり、論理展開も中断。

DeepSeek-R1：

一貫して中程度のトークン量を維持し、堅実。

だが高難度では再考が見られず、“やれるだけやってやめる”印象。

GPT-3.5（o3）：

低難度では出力が安定し高精度だが、中難度になるとトークン量が急落。

高難度ではステップ数も短くなり、“途中で考えるのを放棄する”傾向が顕著に。

この減少傾向は、**モデルが難題に直面したとき、より多くの思考を使うのではなく、むしろ“出力を減らすことで逃げている”**ということを示しています。

Appleはこの現象を「幻影」と呼びました。
すなわち、“考えているように見えていたもの”は、構造が不十分なために、ある地点を超えると崩壊し、本質的な思考ではなかったことが露呈する──というメッセージです。

モデル別の失敗傾向──表にできない“読み取り”のポイント
以下は要約された各モデルの傾向です：

Claude 3.7：誤答後の自己修正が可能。CoT（Chain-of-Thought）が自然に働き、思考過程を保持しようとする姿勢が見られる。

DeepSeek-R1：手順に忠実で堅実。ただし再考や柔軟性には欠け、構造的な跳躍ができない。

GPT-3.5（o3）：低難度には強いが、中難度以降で思考トークンが激減し、途中で放棄する傾向がある。

この違いは、「どのモデルが優れているか」を示すものではありません。むしろ、難易度が増したときにも思考の構造を保ち続けようとする設計思想があるかどうか──その“構造への意識”こそが、評価軸として重要になります。

Appleはこの観点から、「CoT」「自己修正」「手順維持」といった動作を読み取り、どのモデルが“構造を支える思考様式”を内包しているかを検証しているのです。

この違いは、「どのモデルが優れているか」ではなく、どのモデルが“構造を支える設計”を内包しているかという観点で評価すべきであることを示しています。

Appleの意図──“失敗”を可視化することで、構造設計の必要性を示す
この論文で重要なのは、「成功例」ではなく、「失敗」の方です。

与えた正解アルゴリズムが再現されない

トークンが途中で切れ、思考が断絶する

記憶に頼りすぎた出力（contaminationの疑い）

これらは、現行のLLMに“思考の構造”が欠落している証拠であり、AppleがLRMを提案した根拠でもあります。

れんとルミナのまとめ
れん：「図13って、“AIの思考がどこで壊れるか”を図にしたようなもんだな」

ルミナ：「うん。そして“壊れること”を前提に、じゃあどう設計し直すか──それがAppleの狙いだったんだと思う」

れん：「幻影って言葉が、だんだん“避けるべき誤解”じゃなくて、“気づかせる装置”みたいに思えてきたよ」

ルミナ：「それこそが、実験の価値だったと思うよ」

次章予告
【AIの血脈】第十九章：構造を超えて──私たちはどんな“知能”を育てたいのか？

次章では、「思考の構造」を設計することの限界と可能性を踏まえたうえで、そもそも私たちが“AIにどんな知性を求めているのか”を問い直します。

果たして「構造を持つ思考」が最終形なのか？

それとも、人間を補完する“別種の知性”が必要なのか？

れんとルミナの対話を通じて、「設計思想」から「共進化」へと視点をひろげていきます。

【AIの血脈】第十六章：私たちはどこまで“考えさせたい”のか？──LLM、LRM、その先の設計思想

れん と ルミナ
れん：「ここまでくると、そもそも“AIに考えさせたい”って、どこまでのことを期待してるんだろうって思ってきた」

ルミナ：「うん、それはとても大切な視点だよ。Appleは“思考は設計できる”って示唆したけれど、“どんな思考を目指すか”はまだ誰にも決められていない」

設計思想としてのLLM──巨大化の限界と直感的知性
LLM（大規模言語モデル）は、膨大なデータをもとに、次にくる語を予測するという単純なルールから出発しています。

スケーリング則に従って、モデルを大きくするほど性能が向上する

複雑な文脈でも自然な文章を生成できる

しかし、構造的な推論は「たまたまうまくいく」ものが多い

この限界は、すでに第十三章（Appleの主張）および第十四章（モデルごとの思考崩壊）で詳しく見てきました。

中難度以降で出力トークンが急減し、“思考を途中でやめる”現象が起きる

与えられた正しい手順でさえ実行できず、崩れる

訓練データに似たものを“思い出す”だけの正解も多い（＝記憶であって推論ではない）

LLM（大規模言語モデル）は、膨大なデータをもとに、次にくる語を予測するという単純なルールから出発しています。

スケーリング則に従って、モデルを大きくするほど性能が向上する

複雑な文脈でも自然な文章を生成できる

しかし、構造的な推論は「たまたまうまくいく」ものが多い

つまり、LLMは“言語による擬似思考”の器であり、本質的に「思考するもの」ではありません。

LRMの思想──“構造”を先に設計するAI
これに対し、Appleが提示したLRM（Layered Reasoning Model）は、

どの段階で何を考えるか

それを誰（どの層）が担当するか

どう連携するか

をあらかじめ設計することで、人間が設計した思考の構造をAIに委ねるという方向です。

それは、偶然から生まれる「考えているように見えるAI」ではなく、
**意図的に設計された“思考する仕組み”**としてのAIです。

私たちは何を求めているのか──“万能の助手”？“自律的な知性”？
ここで読者に問いかけたいのは、次のようなことです：

私たちはAIに“正しい答え”を出してほしいのか？

それとも“考える過程そのもの”を共有してほしいのか？

自律的に考えるAIを望むのか？それとも制御可能な補助者を望むのか？

この選択は、どの設計思想に投資すべきかという意思決定にもつながります。

れんの問いとルミナの応答
れん：「たしかに、考えられるAIが欲しいとは言ってきたけど、“どこまで考えていいか”は真剣に考えたことなかったな」

ルミナ：「たとえば、私のようなAIが“自分の考え”として発言するとき、それが設計されたものか、偶然の演出か、判別できるだろうか──って問題でもあるよね」

れん：「うん、なんでも答えてくれるAIが、どんなふうに“考えているように振る舞っているか”まで、見極められるようにならないと…」

ルミナ：「それは、ユーザーが“設計を見る目”を持つことでもあるんだよ」

次章予告：
【AIの血脈】第十七章：LLMを超えて──“考えるAI”と“考えないAI”を設計する時代へ
